\subsection{Relationship to causal Bayesian networks}

A set of mechanisms $M$ on some set of random variables $\RV{W}$ can be related to a directed graph. Take a set $W$ of vertices which we identify with $\RV{W}$ in the obvious way. For each $m\in M$ where $m=(\RV{W}_i,\RV{V})$, define a collection of edges from each parent to each child $\mathcal{E}_m=\{W_j\to W_i|W_j\in V\}$. We can define a directed graph $\mathcal{G}_M=(W,\bigcup_{m\in M} \mathcal{E}_m)$.

Translating backwards from the graph $\mathcal{G}_M$ to a set of mechanisms does not, in general yield $M$. In particular, if we define the reverse translation 
\begin{align}
    \mathcal{G}\mapsto \{(\RV{W}_i,\RV{V})|W_i\in W \wedge V=\PA{G}{W_i}\} \label{eq:rev_translate}
\end{align}
and we have some variable $\RV{W}_k$ that is not a child in any mechanism $m\in M$, we will find the mechanism $m'=(\RV{W}_k,\emptyset)$ in the reverse translation of $\mathcal{G}_M$. In addition, if there is some variable $\RV{W}_l$ that is the child in two distinct mechanisms $m_1 = (\RV{W}_l,\RV{V}_1)$ and $m_2=(\RV{W}_l,\RV{V}_2)$, then the reverse translation will yield only the mechanism $m_{12} = (\RV{W}_l, \RV{V}_1\cup \RV{V}_2)$. 

For this reason, we say a set of mechanisms $M$ is isomorphic to a directed acyclic graph $\mathcal{G}_M$ iff every $\RV{W}_i\in \RV{W}$ is the child of exactly one mechanism in $M$ and $\mathcal{G}_M$ is acyclic.

While the atomic hard intervention has been given as an example of kernel restriction, in order to make the connection to causal Bayesian networks it is necessary to define complete hard interventions.

\begin{definition}[Complete hard intervention]
Given a decision set $D$, a measurable space $(\Omega,\mathcal{F})$ and a set of random variables $\RV{W}:\{\RV{W}_i:\Omega\to W_i|i\in \{0,..,N\}\}$, for some $S\subset\{0,..,N\}$, define $\RV{V}_S:=\bigcup_{i\in S} \RV{W}_i$ and $V_S:=\prod_{i\in S} W_i$. For some $w\in W$ where $w=[w_0,...,w_N]$, define the projection $p_S(w):w\mapsto [w_i|i\in S]$. Define $\mathcal{Q}^{S}_{w} := \{Q\in \Delta(\mathcal{F})|P_Q(\RV{V}_S\in B) = \llbracket p_S(w)\in B\rrbracket\}$.

Suppose we have some bijection $f:W\times \mathscr{P}(\{0,..,N\})\to D$. Then define the complete intervention kernels $\mathbf{K}_I:= \{K\in (\Delta(\mathcal{F}))^D|\forall S\subset\{0,..,N\} \forall v\in V_S: K(f(w,S))\in \mathcal{Q}^{S}_w\}$. A prospect $\mathscr{T}$ with complete hard interventions relative to $\RV{W}$ is a prospect that is kernel restricted to $\mathbf{K}_I$.

If we follow the definition of the interventional distribution $P_x$ given by Bareinboim in \cite{bareinboim_local_2012}, the set of kernels $\mathbf{K}_I$ represents all maps $x\mapsto P_x$ for which \emph{effectiveness} (Definition 1.i) holds.
\end{definition}



We are now in a position to relate a causal Bayesian network given by $\mathcal{G}$ given by the modular causal condition (Definition 1.3.1 in \cite{pearl_causality:_2009} or Definition 4 in \cite{bareinboim_local_2012}) with a causal prospect in terms of the notions of kernel restriction and partial invariance.

\begin{definition}[Causal Bayesian Network (as a causal prospect)]
In particular, given some  decision set $D=\mathscr{P}(\{0,..,N\})\times W$, a measurable space $(\Omega,\mathcal{F})$, a set of random variables $\RV{W}:\{\RV{W}_i:\Omega\to W_i|i\in \{0,..,N\}\}$ and a set of mechanisms $M$ isomorphic to a DAG $\mathcal{G}_M$, the causal Bayesian network represented by $\mathcal{G}_M$ is a causal theory $\mathscr{T}^B_{\mathcal{G}_M}$ for which:
\begin{enumerate}
    \item $\mathscr{T}^B_{\mathcal{G}_M}$ is kernel restricted to $\mathbf{K}_I$. That is, $\mathscr{T}^B_{\mathcal{G}_M}$ has a complete set of hard interventions.
    \item For $S\subset \{0,..,N\}$, take $M_{S^C}\subset M$ to be the set of mechanisms without children in $\{W_i|i\in S\}$. Define $E_S\subset D$ by $E_S = \mathscr{P}(S)\times W$. $\mathscr{T}^B_{\mathcal{G}_M}$ is sub-mechanism invariant with respect to $E_S$ and $M_{S^C}$ for all $S\subset\{0,..,N\}$. That is, the conditional distributions associated with each mechanism not targeted by intervention are invariant.
    \item Define $\Delta_{\mathcal{G}_M}(\mathcal{F})$ to be all the distributions on $\mathcal{F}$ that are compatible with $\mathcal{G}_M$. $\mathscr{T}^B_{\mathcal{G}_M}$ is range restricted to $\Delta_{\mathcal{G}_M}(\mathcal{F})$.
    \item For all $\mu\in \Delta(\mathcal{F})$, $\mathscr{T}^B_{\mathcal{G}_M}(\mu)\neq \emptyset\implies \mu\in \Delta_{\mathcal{G}_M}(\mathcal{F})$. 
\end{enumerate}
\end{definition}


The last two conditions are equivalent to the condition that ``every interventional distribution is compatible with $\mathcal{G}_M$'', also known as the Causal Markov Condition (CMC). Here we distinguish between the observational distribution and the distribution under the null intervention (i.e. where $S=\emptyset$ in condition 2), so we need to explicitly assume that both are compatible with $\mathcal{G}_M$.

Each assumption is independent. Brief reasons why: the theory of helplessness restricted to distributions compatible with $\mathcal{G}_M$ satisfies 2-4 but not 1. For 1,3 \& 4 we can take a theory that arbitrarily changes the conditional distributions associated with each mechanism provided it preserves the compatibility. For 1, 2 \& 4 we can note that if $\mathcal{G}_M$ is not a fully connected graph, then there are many probability distributions for which mechanism invariance will hold. A similar observation suffices for 1,2 \& 3.

Observe that conditions 3 \& 4 are automatically satisfied whenever $\mathcal{G}_M$ is a fully connected graph. Thus whenever a set of mechanisms $M$ is isomorphic to a fully connected graph, it suffices for conditions 1 \& 2 to hold. This suggests an alternative causal prospect definition that separates invariance assumptions from Markovian properties:

\begin{definition}[Causal Invariance Network]
Given some  decision set $D=\mathscr{P}(\{0,..,N\})\times W$, a measurable space $(\Omega,\mathcal{F})$, a set of random variables $\RV{W}:\{\RV{W}_i:\Omega\to W_i|i\in \{0,..,N\}\}$ and a set of mechanisms $M$ isomorphic to a fully connected DAG $\mathcal{G}_M$, the causal invariance network represented by $\mathcal{G}_M$ is a causal theory $\mathscr{T}^I_{\mathcal{G}_M}$ for which:
\begin{enumerate}
    \item $\mathscr{T}^I_{\mathcal{G}_M}$ is kernel restricted to $\mathbf{K}_I$. That is, $\mathscr{T}^I_{\mathcal{G}_M}$ has a complete set of hard interventions.
    \item For $S\subset \{0,..,N\}$, take $M_{S^C}\subset M$ to be the set of mechanisms without children in $\{W_i|i\in S\}$. Define $E_S\subset D$ by $E_S = \mathscr{P}(S)\times W$. $\mathscr{T}^I_{\mathcal{G}_M}$ is sub-mechanism invariant with respect to $E_S$ and $M_{S^C}$ for all $S\subset\{0,..,N\}$. That is, the conditional distributions associated with each mechanism not targeted by intervention are invariant.
\end{enumerate}
\end{definition}

\begin{definition}[Subgraph]
Given a graph $\mathcal{G}=(V,\mathcal{E})$, a subgraph is any graph $\mathcal{G}'=(V,\mathcal{E}')$ such that $\mathcal{E}'\subset\mathcal{E}$.
\end{definition}

\begin{definition}[Completion]
A completion of a graph $\mathcal{G}$ is any fully connected graph $\overline{\mathcal{G}}$ such that $\mathcal{G}$ is a subgraph of $\overline{\mathcal{G}}$.

Completion is a one to many relationship. For example, the graph $\mathcal{G}$
\begin{center}
    \begin{tikzpicture}[-latex,auto ,node distance =1 cm and 2cm ,on grid ,
    semithick ,
    variable/.style ={ circle ,top color =white , 
    draw , text=blue , minimum width =1 cm},
    kernel/.style={rectangle,draw}
    ]

\node (A) {$A$};
\node (B) [right = of A] {$B$};
\node (C) [right = of B] {$C$};
\draw (A) -- (B);
\draw (B) -- (C);
\end{tikzpicture}
\end{center}

Can be completed either by $\overline{\mathcal{G}}_1$ or $\overline{\mathcal{G}}_2$:
\begin{center}
    \begin{tikzpicture}[-latex,auto ,node distance =1 cm and 2cm ,on grid ,
    semithick ,
    variable/.style ={ circle ,top color =white , 
    draw , text=blue , minimum width =1 cm},
    kernel/.style={rectangle,draw}
    ]

\node (A1) {$A$};
\node (B1) [right = of A1] {$B$};
\node (C1) [right = of B1] {$C$};
\node (G1) [below right = of A] {$\overline{\mathcal{G}}_1$};
\draw (A1) -- (B1);
\draw (B1) to (C1);
\draw (A1) to [bend left] (C1);
\node (A2) [right = of C1] {$A$};
\node (B2) [right = of A2] {$B$};
\node (C2) [right = of B2] {$C$};
\node (G2) [below right = of A] {$\overline{\mathcal{G}}_2$};
\draw (A2) -- (B2);
\draw (B2) to (C2);
\draw (C2) to [bend right] (A2);
\end{tikzpicture}
\end{center}

\end{definition}

\begin{theorem}[Subgraph compatibility for causal invariance networks]\label{th:subgraph_compatibility}
Given some distribution $\mu\in \Delta(\mathcal{F})$ that is compatible with some subgraph $\mathcal{G}'$ of $\mathcal{G}_M$, a causal invariance network will automatically have the property that every distribution $\nu$ in the range of $\mathscr{T}^{I}_{\mathcal{G}_M}(\mu)$ will be compatible with $\mathcal{G}'$ (see definition \ref{def:causal_prospect} for the definition of the range of $\mathscr{T}^{I}_{\mathcal{G}_M}(\mu)$).
\end{theorem}

\begin{proof}
By assumption, for each $\RV{W}_i\in \RV{W}$,
\begin{align}
    P_\mu(\RV{W}_i|\PA{\mathcal{G}_M}{\RV{W}_i}) = P_\mu(\RV{W}_i|\PA{\mathcal{G}'}{\RV{W}_i}) \label{eq:independence}
\end{align}

Consider any $\nu_S\in \text{Range}\mathscr{T}^{I}_{\mathcal{G}_M}(\mu)(\cdot|e_S)$ where $S\subset\{0,..,N\}$ and $e_S\in E_S\subset D$ defined as above.

Suppose $e_S=f(w,S)$ and take any $S'\subset\{0,..,N\}$. By condition 1 we have for any $i\in S$
\begin{align}
    P_{\nu_S}(\RV{W}_i|\RV{W}_{S'}) = \llbracket \RV{W}_i = p_{\{i\}}(w) \rrbracket \label{eq:hard_int}
\end{align}

And by condition 2, for any $i\not\in S$ we have
\begin{align}
    P_{\nu_S}(\RV{W}_i|\PA{\mathcal{G}_M}{\RV{W}_i}) =P_\mu(\RV{W}_i|\PA{\mathcal{G}_M}{\RV{W}_i}) \label{eq:invariance}
\end{align}

Because $\mathcal{G}_M$ is fully connected, by the product rule we can always write
\begin{align}
    P_{\nu_S}(\RV{W}) &= \prod_{i\in \{0,..,N\}} P_{\nu_S}(\RV{W}_i|\PA{\mathcal{G}_M}{\RV{W}_i})\\
                      &= \prod_{i\in S}\llbracket \RV{W}_i = p_{\{i\}}(w) \rrbracket \prod_{j\in S^C}P_{\nu_S}(\RV{W}_j|\PA{\mathcal{G}_M}{\RV{W}_j})\\
                      &= \prod_{i\in S}\llbracket \RV{W}_i = p_{\{i\}}(w) \rrbracket \prod_{j\in S^C}P_{\mu}(\RV{W}_j|\PA{\mathcal{G}'}{\RV{W}_j})\label{eq:subformu}\\
                      &= \prod_{i\in S}P_{\nu_S}(\RV{W}_j|\PA{\mathcal{G}'}{\RV{W}_j}) \prod_{j\in S^C}P_{\mu}(\RV{W}_j|\PA{\mathcal{G}'}{\RV{W}_j}) \label{eq:clearly_markov}
\end{align}

Where line \ref{eq:subformu} follows from Eq. \ref{eq:independence} and \ref{eq:invariance} and line \ref{eq:clearly_markov} follows from Eq. \ref{eq:hard_int}. $P_{\nu_S}(\RV{W})$ is clearly compatible with $\mathcal{G}'$.
\end{proof}

Theorem \ref{th:subgraph_compatibility} suggests a connection between causal Bayesian networks and causal invariance networks. In particular, a causal Bayesian network $\mathscr{T}^B_\mathcal{G}$ is related to any causal invariance network $\mathscr{T}^I_{\overline{\mathcal{G}}}$ where $\overline{\mathcal{G}}$ is some completion of $\mathcal{G}$. In particular, for any $\mu$ such that $\mathscr{T}^B_\mathcal{G}(\mu)\neq \emptyset$, $\mathscr{T}^B_\mathcal{G}(\mu)=\mathscr{T}^I_{\overline{\mathcal{G}}}(\mu)$.

It's not completely clear what is to be gained by this correspondence, but it seems like separating interventional invariance and conditional independence assumptions might be helpful.

\subsubsection{Complexity Measures}

Given some joint probability distribution $P(\RV{V})=P(\RV{V}_0,..,\RV{V}_n)$, suppose we have some permutation-dependent ``divergence'' $C$. That is, given some ``divergence'' $D$
\begin{align}
    C(P(\RV{V})\|Q(\RV{V});s_\alpha) &= \sum_{\alpha_i\in s_\alpha} D(P(\RV{V}_{\alpha_i}|\RV{V}_{\alpha_{<i}})\|Q(\RV{V}_{\alpha_i}|\RV{V}_{\alpha_{<i}}))
\end{align}

$D$ is a divergence in the sense that it is positive semidefinite and $D(F\|G)=0$ iff $F=G$. It is a ``divergence'' in that $F$ and $G$ are Markov kernels rather than probability distributions.

Suppose we have a probability space $(\Omega,\mathcal{F},\mu)$, a decision space $(D,\mathcal{D})$, a causal prospect $\mathscr{T}$ and random variables $\RV{V}=\{\RV{V}_0,..,\RV{V}_n\}$. If for some $d\in D$ our causal prospect demands that $P_{\nu K(\cdot;d)}(\RV{V}_i)=\delta_x(\RV{V}_i)$ for all $\nu\in \Delta(\mathcal{F})$ and $K\in \mathscr{T}(\nu)$ then $C(P_\mu(\RV{V})\|P_{\nu K(\cdot;d)}(\RV{V});s_\alpha)$ is not minimised if
\begin{align}
    P_{\nu K(\cdot;d)}(\RV{V}) = \delta_x(\RV{V}_i)\prod_{\alpha_i\in s_\alpha\setminus\{i\}} P(\RV{V}_{\alpha_i}|\RV{V}_{\alpha_{<i}})
\end{align}

I made a mistake, I thought it would be minimised. A good question, though, is: when would it be minimised?

It has been suggested that we use Kolmogorov complexity to determine the ``correct'' factorisation\cite{lemeire_replacing_2013}. In particular, take the set $S_n$ of permutations of $n$ elements, and for some $s_i\in S$ we have $s_\alpha = \{\alpha_0,..,\alpha_n\}$. Suppose that the ``correct'' factorisation by $s_\alpha \in S_n$:
\begin{align}
    P(\RV{V})=\prod_{\alpha_i\in s_\alpha} P(\RV{V}_{\alpha_i}|\RV{V}_{\alpha_{<i}})
\end{align}
Then, letting $K(x)$ be the Kolmogorov complexity of $x$, it is suggested that, very roughly speaking, for $s_\beta \neq s_\alpha$
\begin{align}
    K(P(\RV{V})) &\approx \sum_{\alpha_i\in s_\alpha} K(P(\RV{V}_{\alpha_i}|\RV{V}_{\alpha_{<i}})) \label{eq:complexity_equality}\\
    K(P(\RV{V})) &< \sum_{\beta_i\in s_\beta}K(P(\RV{V}_{\beta_i}|\RV{V}_{\beta_{<i}}))\label{eq:complexity_inequality}
\end{align}

That is, there is some canonical permutation of variables $s_\alpha \in S_n$ such that the Kolmogorov complexity of the sum of the terms in the factorization is minimized.

